{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transliteration.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1XPxre_ConUl5wrxd6tTNDU6WVqx6VpE8",
      "authorship_tag": "ABX9TyMXxT7AkpIVmYF9beNzV6lU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agrawalsourav98/SignboardTranslation/blob/main/transliteration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNmoMsLaHKap"
      },
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import dataset\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRefrQPdHaL_"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usWZSR3wHc6p"
      },
      "source": [
        "## Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM9J5B6-HcNZ"
      },
      "source": [
        "!cp /content/drive/MyDrive/PadhAI/NEWS2012-Training-EnHi-13937.xml ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWQPNmYFMoFt"
      },
      "source": [
        "## Create hindi vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZQN4eFqMq2p"
      },
      "source": [
        "hindi_alphabets = {}\n",
        "hindi_alphabets['-pad-'] = 0\n",
        "for i in range(2304,2432):\n",
        "  hindi_alphabets[chr(i)] = i - 2304 + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ercncuPINHB3",
        "outputId": "f76ecf00-7688-4dec-ce34-cbfd7630789b"
      },
      "source": [
        "print(len(hindi_alphabets))\n",
        "print(hindi_alphabets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "129\n",
            "{'-pad-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwTi9aFlLBej"
      },
      "source": [
        "## Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVUK9z3vLEmZ"
      },
      "source": [
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "def cleanEnglishVocab(line):\n",
        "\n",
        "  line = line.replace('-',' ').replace(',',' ').upper()\n",
        "  line = non_eng_letters_regex.sub('',line)\n",
        "\n",
        "  return line.split()\n",
        "\n",
        "def cleanHindiVocab(line,vocabulary):\n",
        "\n",
        "  line = line.replace('-',' ').replace(',',' ')\n",
        "  cleaned_line = ''\n",
        "\n",
        "  for c in line:\n",
        "    if c not in vocabulary and c != ' ':\n",
        "      continue\n",
        "    cleaned_line += c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8tX6_GvI-NL"
      },
      "source": [
        "## Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "3WKD8bQSOIve",
        "outputId": "cff56110-7060-42f5-8fca-aa9674e4e4c8"
      },
      "source": [
        "class TransliterationDataset(dataset):\n",
        "\n",
        "  def __init__(self,filename):\n",
        "    super(TransliterationDataset,self).__init__()\n",
        "\n",
        "    self.english_words, self.hindi_words = self.readXMLFile(filename, cleanHindiVocab)\n",
        "    self.shuffle_indices = list(range(len(english_words)))\n",
        "    random.shuffle(self.shuffle_indices)\n",
        "    self.shuffle_start_index = 0\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.english_words)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.english_words[idx], self.hindi_words[idx]\n",
        "\n",
        "  def readXMLFile(self, filename, lang_vocab_cleaner):\n",
        "\n",
        "    filename = Path(filename).expanduser().absolute()\n",
        "\n",
        "    tree = ET.parse(filename)\n",
        "    transliterationCorpus = tree.getroot()\n",
        "    lang1_words = []\n",
        "    lang2_words = []\n",
        "\n",
        "    for line in transliterationCorpus:\n",
        "      wordlist_1 = cleanEnglishVocab(line[0].text)\n",
        "      wordlist_2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "      if len(wordlist_1) != len(wordlist_2):\n",
        "        print(\"Skipping: {0}-{1}\".format(wordlist_1,wordlist_2))\n",
        "        continue\n",
        "      \n",
        "      for word in wordlist_1:\n",
        "        lang1_words.append(word)\n",
        "\n",
        "      for word in wordlist_2:\n",
        "        lang2_words.append(word)\n",
        "\n",
        "    \n",
        "    return lang1_words, lang2_words\n",
        "\n",
        "  def get_random_sample(self):\n",
        "    return self.__getitem__(random.ran)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-c02fdb41f9ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTransliterationDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransliterationDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: module.__init__() takes at most 2 arguments (3 given)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBD7c70hJAcj"
      },
      "source": [
        "def processXML(filename):\n",
        "  filename = Path(filename).expanduser().absolute()\n",
        "\n",
        "  tree = ET.parse(filename)\n",
        "  root = tree.getroot()\n",
        "  print(root)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOqnKiStJ3DN",
        "outputId": "30cd118a-1698-4feb-88cd-c40527f3bd10"
      },
      "source": [
        "processXML('/content/NEWS2012-Training-EnHi-13937.xml')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Element 'TransliterationCorpus' at 0x7f8ba1374c28>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}